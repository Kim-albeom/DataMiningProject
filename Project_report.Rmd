---
title: "Breast cancer diagnosis using scorecard"
author: "티타임"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: simplex
    fig.width: 10
    fig.height: 10
    toc: yes
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 0. 서론

Breast Cancer Wisconsin(Diagnostic) Data set은 주사기로 종양에서 세포를 흡인해서 현미경으로 세포를 관찰해 그 특징들을 mean, se, worst로 정리한 데이터 셋입니다. 저희는 이 데이터를 통해서 양성 종양과 악성 종양을 정확하게 구분할 수 있는 모델을 구현하고자 합니다. 이를 통해 오진율을 줄이는 것을 목표로 잡았습니다.

### 0-1. 패키지 불러오기

```{r, message=FALSE}
# plotting and reshaping data
library(tidyverse)
library(GGally)
library(reshape)

# Correlation
library(corrplot)

# Confusion Matrix
library(caret)

# ROC Curve
library(ROCR)

# Model
library(rpart)
library(rpart.plot)
library(randomForest)

# Plot combine
library(gridExtra)
```

<br><br><br>

## 1. 데이터 불러오기 및 확인

* 데이터 출처
    - [UCI Machine Learning Repository - Breast Cancer Wisconsin (Diagnosis)](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic)
    - [kaggle UCI MACHINE LEARNING - Breast Cancer Wisconsin (Diagnosis) Data set](https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data)

```{r}
# 데이터 불러오기
breast_cancer_data <- read.csv(".//data//breast_cancer.csv")

# 데이터 확인하기.
str(breast_cancer_data)
```

현재 `diagnosis` 변수가 char형 변수로 되어 있기 때문에 분석을 위해서 factor형으로 변경하겠습니다. 그러나 그 전에 결측치가 있는지 확인을 하고 있다면 제거를 해주겠습니다.

<br>

### 1-1. 결측치 확인.

```{r}
# 각 변수열 별 결측치 개수 확인.
colSums(is.na(breast_cancer_data))
```

결과를 봤을 때, `X`라는 변수 열의 모든 값이 결측치인 것을 확인할 수 있습니다. 따라서 `X` 변수열(33)을 제거해주도록 하겠습니다.

<br>

```{r}
breast_cancer_data = subset(breast_cancer_data, select=c(-33))

colnames(breast_cancer_data)
```

-   **Breast_Cancer 데이터**
    -   **변수**(총 33가지)
        -   **id**(1)
        -   **diagnosis**(2): Benign(양성=B), Malignant(악성=M)
        -   **radius_mean, se, worst**(3, 13, 23): 중심에서 둘레까지의 거리의 평균, 표준오차, 최대값
        -   **texture_mean, se, worst**(4, 14, 24): gray-scale 값의 표준편차의 평균, 표준오차, 최대값
        -   **perimeter_mean, se, worst**(5, 15, 25): 핵 종양의 크기의 평균, 표준오차, 최대값
        -   **area_mean, se, worst**(6, 16, 26): 핵 종양의 면적의 평균, 표준오차, 최대값
        -   **smoothness_mean, se, worst**(7, 17, 27): 반지름 길이의 지역 변동의 평균, 표준오차, 최대값
        -   **compactness_mean, se, worst**(8, 18, 28): $radius^2/area-1.0$의 평균, 표준오차, 최대값
        -   **concavity_mean, se, worst**(9, 19, 29): 등고선의 오목한 부분의 심각도 평균, 표준오차, 최대값
        -   **concave.points_mean, se, worst**(10, 20, 30): 등고선의 오목한 부분의 수의 평균, 표준오차, 최대값
        -   **symmetry_mean, se, worst**(11, 21, 31): 대칭성의 평균, 표준오차, 최대값
        -   **fractal_dimension_mean, se, worst**(12, 22, 32): $coastline approximation^{-1}$(해안선 근사치의 역수)의 평균, 표준오차, 최대값
        -   **X**(33): 미 기재 변수

<br><br>

### 1-2. diagnosis 변수를 factor로 변환

```{r}
# diagnosis를 char에서 factor로 변환
breast_cancer_data$diagnosis = as.factor(breast_cancer_data$diagnosis)

str(breast_cancer_data)
```

`diagnosis` 변수가 이제 factor로 변환된 것이 확인됩니다.

<br><br>

### 1-3. diagnosis 변수의 분포

`diagnosis`의 결과인 `Benign`, `Malignant`에 관측데이터가 얼마나 할당되어 있는지 확인하겠습니다.

```{r}
# 전체 및 진단 별 데이터의 수
T_count = nrow(breast_cancer_data)
B_count = nrow(breast_cancer_data %>% filter(diagnosis == "B"))
M_count = T_count - B_count

# 진단 별 데이터의 비율
B_prob = B_count / T_count
M_prob = M_count / T_count

diag_dist = data.frame(result = c("Benign", "Malignant"), 
                       count = c(B_count, M_count),
                       prob = c(B_prob, M_prob))

# 결과
print(diag_dist)

# barplot으로 시각화
ggplot(diag_dist, aes(x=result, y=prob, fill=result)) +
  geom_bar(stat="identity", width=0.5) +
  geom_text(aes(label=sprintf("%d", count)), position=position_stack(vjust = 0.5), color="black", size=5) +
  labs(title="Comparing data count between Benign and Malignant", y="Prob", x="") +
  scale_fill_manual(values = c("Benign"= "#F2ABA6", "Malignant"="#6AD3D6")) +
  coord_flip() +
  theme(legend.position = "none")
```

위 처럼 양성(`Benign`)의 데이터가 악성(`Malignant`)보다 데이터가 더 많다는 것을 확인할 수 있습니다.

<br><br><br>

## 2. 분포에 대한 시각화

데이터를 통한 분석 및 모델링 이전에 다중공선성 문제 해결을 위한 1차 변수 선택을 위해 변수 간의 상관성을 확인해 보겠습니다. 상관성에 대한 기준은 아래와 같이 정했습니다.

-   $\rho$의 기준(절대값)
    -   $\rho \ge 0.8$: 높은 상관성
    -   $0.4 \le \rho \lt 0.8$: 중간 정도의 상관성
    -   $\rho \lt 0.4$: 약한 상관성

<br><br>

### 2-1. 같은 변수에 대한 다른 지표 변수 간 상관성 {.tabset}

#### Radius

```{r}
 ggpairs(breast_cancer_data[,c(3, 13, 23, 2)],
        aes(color=diagnosis, alpha=0.3),
        lower=list(combo=wrap("facethist", binwidth=0.5)),
        upper=list(continuous = wrap("cor", size=3))) +
  labs(title="Radius Plot and Correlation") +
  theme(plot.title=element_text(face="bold", color="black", hjust=0.5, size=10))
```

radius에서 mean과 worst 간의 상관성이 강하게 나오고, mean과 se, se와 worst 간에는 약하지는 않지만 중간 정도의 상관성을 보인다.

#### Texture

```{r}
ggpairs(breast_cancer_data[,c(4, 14, 24, 2)],
        aes(color=diagnosis, alpha=0.3),
        lower=list(combo=wrap("facethist", binwidth=0.5)),
        upper=list(continuous = wrap("cor", size=3))) +
  labs(title="texture Plot and Correlation") +
  theme(plot.title=element_text(face="bold", color="black", hjust=0.5, size=10))

```

texture에서 mean과 worst 간의 상관성이 강하게 나오고, mean과 se, se와 worst 간에는 약한 상관성을 보인다.

#### Perimeter

```{r}
ggpairs(breast_cancer_data[,c(5, 15, 25, 2)],
        aes(color=diagnosis, alpha=0.3),
        lower=list(combo=wrap("facethist", binwidth=0.5)),
        upper=list(continuous = wrap("cor", size=3))) +
  labs(title="Perimeter Plot and Correlation") +
  theme(plot.title=element_text(face="bold", color="black", hjust=0.5, size=10))
```

perimeter에서 mean과 worst 간의 상관성이 강하게 나오고, mean과 se, se와 worst 간에는 약하지는 않지만 어느 정도 중간 정도의 상관성을 보인다.

#### Area

```{r}
ggpairs(breast_cancer_data[,c(6, 16, 26, 2)],
        aes(color=diagnosis, alpha=0.3),
        lower=list(combo=wrap("facethist", binwidth=0.5)),
        upper=list(continuous = wrap("cor", size=3))) +
  labs(title="Area Plot and Correlation") +
  theme(plot.title=element_text(face="bold", color="black", hjust=0.5, size=10))
```

area에서 mean, se, worst 간 상관성이 높게 나온다.

#### smoothness

```{r}
ggpairs(breast_cancer_data[,c(7, 17, 27, 2)],
        aes(color=diagnosis, alpha=0.3),
        lower=list(combo=wrap("facethist", binwidth=0.5)),
        upper=list(continuous = wrap("cor", size=3))) +
  labs(title="Smoothness Plot and Correlation") +
  theme(plot.title=element_text(face="bold", color="black", hjust=0.5, size=10))
```

area에서 mean과 worst 간 상관성은 높게 나오나, mean과 se, se와 worst 간의 상관성은 낮게 나온다.

#### compactness

```{r}
ggpairs(breast_cancer_data[,c(8, 18, 28, 2)],
        aes(color=diagnosis, alpha=0.3),
        lower=list(combo=wrap("facethist", binwidth=0.5)),
        upper=list(continuous = wrap("cor", size=3))) +
  labs(title="Compactness Plot and Correlation") +
  theme(plot.title=element_text(face="bold", color="black", hjust=0.5, size=10))
```

compactness에서 mean과 worst 간 상관성은 높게 나오고, mean과 se, se와 worst 간에는 중간 정도의 상관성이 나온다.

#### concavity

```{r}
ggpairs(breast_cancer_data[,c(9, 19, 29, 2)],
        aes(color=diagnosis, alpha=0.3),
        lower=list(combo=wrap("facethist", binwidth=0.5)),
        upper=list(continuous = wrap("cor", size=3))) +
  labs(title="Concavity Plot and Correlation") +
  theme(plot.title=element_text(face="bold", color="black", hjust=0.5, size=10))
```

concavity에서 mean과 worst 간 상관성은 높게 나오고, mean과 se, se와 worst 간에는 중간 정도의 상관성이 나온다.

#### concave.points

```{r}
ggpairs(breast_cancer_data[,c(10, 20, 30, 2)],
        aes(color=diagnosis, alpha=0.3),
        lower=list(combo=wrap("facethist", binwidth=0.5)),
        upper=list(continuous = wrap("cor", size=3))) +
  labs(title="Concave.points Plot and Correlation") +
  theme(plot.title=element_text(face="bold", color="black", hjust=0.5, size=10))
```

concave.points에서 mean과 worst 간 상관성은 높게 나오고, mean과 se, se와 worst 간에는 중간 정도의 상관성이 나온다.

#### symmetry

```{r}
ggpairs(breast_cancer_data[,c(11, 21, 31, 2)],
        aes(color=diagnosis, alpha=0.3),
        lower=list(combo=wrap("facethist", binwidth=0.5)),
        upper=list(continuous = wrap("cor", size=3))) +
  labs(title="Symmetry Plot and Correlation") +
  theme(plot.title=element_text(face="bold", color="black", hjust=0.5, size=10))
```

symmetry에서 mean과 worst 간에는 중간정도의 상관성, mean과 se, se와 worst 간에는 낮은 상관성을 보인다다.

#### fractal.dimension

```{r}
ggpairs(breast_cancer_data[,c(12, 22, 32, 2)],
        aes(color=diagnosis, alpha=0.3),
        lower=list(combo=wrap("facethist", binwidth=0.5)),
        upper=list(continuous = wrap("cor", size=3))) +
  labs(title="Fractal.dimension Plot and Correlation") +
  theme(plot.title=element_text(face="bold", color="black", hjust=0.5, size=10))
```

fractal.dimension에서 mean, se, worst 간에는 중간 정도의 상관성을 보인다.

###  {.unnumbered}

<br>

> mean과 worst 간의 상관계수는 모두 0.7이상, 그 중 대부분이 0.8이상의 높은 상관성을 보였습니다. 그러나 mean과 se, se와 worst 간의 상관계수는 중간 혹은 그 이하의 상관성이 나와 (mean se worst) 3가지 그룹 30개의 변수에서 (mean se) 2개의 그룹의 변수만을 선택해서 진행하도록 하겠습니다.

<br>

```{r}
breast_cancer_data = subset(breast_cancer_data, select=c(1:22)) # worst 그룹을 제거
```

<br><br>

### 2-2. 그룹별 내부 변수 간 상관성(worst 그룹 제외). {.tabset}

#### mean group

```{r, fig.width=15, fig.height=15}
corrplot(cor(breast_cancer_data[,c(3:12)]),
         type ="upper",
         order = "original",
         tl.col = "black",
         addCoef.col = "white",
         number.cex = 2,
         tl.cex = 2,
         title = "Mean Correlation",
         cex.main=4,
         cl.cex=2,
         diag=F,
         mar=c(0,0,5,0))
  
```

(radius perimeter area) 간의 상관계수가 0.8을 넘어 높은 상관성을 보이고, (compactness concavity concave.points) 간의 상관계수도 0.8을 넘어 높은 상관성을 보입니다.. 이 외에도 (area concave.points), (perimeter concave.points) (radius concave.points)가 0.8을 넘어 높은 상관성을 보입니다.

#### se group

```{r, fig.width=15, fig.height=15}
corrplot(cor(breast_cancer_data[,c(13:22)]),
         type ="upper",
         order = "original",
         tl.col = "black",
         addCoef.col = "white",
         number.cex = 2,
         cl.cex= 2,
         tl.cex = 2,
         title = "SE Correlation",
         cex.main = 4,
         diag=F,
         mar=c(0,0,5,0))
```

(radius perimeter area) 간의 상관계수가 0.8을 넘어 높은 상관성을 보이고, (compactness concavity concave.points) 간의 상관계수도 0.7을 넘어 어느 정도 높은 상관성을 보입니다. 이 외에도 (compactness fractal.dimension)의 상관계수가 0.8을 넘어 높은 상관성을 보입니다.

###  {.unnumbered}

<br>

> (radius perimeter area), (compactness concavity concave.points) 두 가지 그룹에 대해서 내부 변수 간의 상관성이 높게 나오는 것이 확인됩니다.

> 따라서 (radius perimeter area)에서 radius만을, (compactness concavity concave.points)에서 compactness만을 선택해서 mean, se 2개 그룹의 (radius texture smoothness compactness symmetry fractal.dimension) 총 12개의 변수를 최종 선택하겠습니다.

<br>

```{r}
data_selected = breast_cancer_data %>% select(!contains(c("perimeter", "area", "concavity", "concave.points")))


colnames(data_selected) # id와 diagnosis를 제외한 나머지가 선택된 변수
```

-   선택된 변수(12개)
    -   radius_mean, radius_se
    -   texture_mean, texture_se
    -   smoothness_mean, smoothness_se
    -   compactness_mean, compactness_se
    -   symmetry_mean, symmetry_se
    -   fractal_dimension_mean, fractal_dimension_se

<br><br>

### 2-3. diagnosis에 따른 변수들의 분포

#### 2-3-1. mean {.tabset}

##### box plot

```{r}
breast_melt1 = melt(data_selected[,c(2:8)], id.vars = "diagnosis")
ggplot(breast_melt1, aes(x=variable, y=value)) +
  geom_boxplot(aes(alpha=0.3,fill=diagnosis)) +
  facet_wrap(~variable,scale="free")
```

##### density plot

```{r}
ggplot(breast_melt1, aes(x=value, groups=variable)) +
  geom_density(aes(alpha=0.3,fill=diagnosis)) +
  facet_wrap(~variable,scale="free")
```

<br><br><br>

#### 2-3-2. se {.tabset}

##### boxplot

```{r}
breast_melt2 = melt(data_selected[,c(2,9:14)], id.vars = "diagnosis")
ggplot(breast_melt1, aes(x=variable, y=value)) +
  geom_boxplot(aes(alpha=0.3,fill=diagnosis)) +
  facet_wrap(~variable,scale="free")
```

##### density plot

```{r}
ggplot(breast_melt2, aes(x=value, groups=variable)) +
  geom_density(aes(alpha=0.3,fill=diagnosis)) +
  facet_wrap(~variable,scale="free")
```

####  {.unnumbered}

> 양성("B", "Benign")일 때보다 악성("M", "Malignant")일 때, 각 변수에 대해서 평균 값이 더 크게 나옵니다. 또한 분포 자체가 더 큰 쪽으로 분포되어있습니다.

> 따라서 악성 종양인 사람이 양성보다 종양의 크기면에서도 더욱 크고, 더 불규칙적인 형태라는 것을 생각할 수 있습니다.

<br><br><br>

## 3. Modeling

먼저 569EA의 데이터를 train(70%), validation(30%)로 나눠주겠습니다.

-   train_index: 전체 데이터 중 70%를 샘플링한 데이터
-   breast_cancer_train: train 데이터
-   breast_cancer_valid: validation 데이터

```{r}
set.seed(123)

# 고정된 인덱스 생성
fixed_index = sample(1:T_count)

# train과 valid의 비율을 7:3 으로 설정
train_ratio = 0.7
train_rows = round(T_count * train_ratio)

# 고정된 인덱스에서 train 데이터의 인덱스 선택
train_index = fixed_index[1:train_rows]

# train과 valid로 데이터 나누기.
breast_cancer_train = data_selected[train_index,]
breast_cancer_valid = data_selected[-train_index,]

train_count = train_rows
valid_count = T_count - train_count

cat("train data: ", train_count, "EA\n", "validation data: ", valid_count, "EA")
```

<br><br>

### 3-1. Comparing ML Model

1차적인 변수 선택을 통해 선택된 변수들을 가지고 모델링을 하겠습니다. 모델은 $Logistic\ Regression, Decision\ Tree,\ Random\ Forest$ 3가지로 진행하겠습니다.

```{r, warning=FALSE}
# formula 설정
formula = diagnosis ~ 
  radius_mean + texture_mean + smoothness_mean + 
  compactness_mean + symmetry_mean +fractal_dimension_mean + 
  radius_se + texture_se + smoothness_se + compactness_se + 
  symmetry_se + fractal_dimension_se 

# Model 학습
logit_cancer = glm(formula, data = breast_cancer_train, family = binomial)
tree_cancer = rpart(formula, data = breast_cancer_train, method="class")
rf_cancer = randomForest(diagnosis ~ ., data = breast_cancer_train)
```

<br><br>

#### 3-1-1. Compare Accuracy

먼저 정확도를 비교하겠습니다.

```{r}
# 각 모델에 대한 예측 생성
logit_pred_acc = predict(logit_cancer, newdata = breast_cancer_valid, type="response")
tree_pred_acc = predict(tree_cancer, newdata = breast_cancer_valid, type = "class")
rf_pred_acc = predict(rf_cancer, newdata = breast_cancer_valid)

# 예측을 이진 클래스로 변환
logit_pred_class = ifelse(logit_pred_acc > 0.5, "M", "B")

# Accuracy 계산
logit_acc = mean(logit_pred_class == breast_cancer_valid$diagnosis)
tree_acc = mean(tree_pred_acc == breast_cancer_valid$diagnosis)
rf_acc = mean(rf_pred_acc == breast_cancer_valid$diagnosis)

# Accuracy를 data frame으로 변환
acc_df = data.frame(Model = c("Logistic Regression", "Decision Tree", "Random Forest"),
                    Accuracy = c(logit_acc, tree_acc, rf_acc))

# Model 변수를 factor화하고 level을 지정
acc_df$Model = factor(acc_df$Model, levels=c("Random Forest", "Decision Tree", "Logistic Regression"))

# 색상을 지정
colors = c("#0000FF80", "#FF000080", "#00800080")

# barplot으로 시각화
ggplot(acc_df, aes(x=Model, y=Accuracy, fill=Model)) +
  geom_bar(stat="identity", width=0.5, fill=colors) +
  ylim(0,1) +
  geom_text(aes(label=round(Accuracy, 4)), size = 5, vjust=-0.5) +
  coord_flip() +
  labs(title="Comparison of Model Accuracy", x="Model", y="Accuracy") +
  theme_bw() +
  theme(legend.position="none", axis.title.y = element_blank())
```

각 모델에 대해서 정확도를 구하고 시각화를 했습니다. 위와 같이 $Decision\ Tree \lt Random\ Forest \lt Logistic\ Regression$ 순서로 정확도의 성능을 보입니다. 그러나 여기서 $Random\  Forest$ 와 $Logistic\  Regression$의 정확도가 비슷하게 나와 **AUROC** 도 비교해보도록 하겠습니다.

<br><br>

#### 3-1-2. Compare ROC and AUROC

##### ROC Curve

```{r, warning=FALSE}
# 각 모델에 대한 예측 생성
logit_pred_roc <- predict(logit_cancer, newdata = breast_cancer_valid, type = "response")
tree_pred_roc <- predict(tree_cancer, newdata = breast_cancer_valid, type = "prob")[,2]
rf_pred_roc <- predict(rf_cancer, newdata = breast_cancer_valid, type = "prob")[,2]

# 예측 결과와 실제 레이블을 사용하여 예측 객체를 생성합니다
pred_logit <- prediction(logit_pred_roc, breast_cancer_valid$diagnosis)
pred_tree <- prediction(tree_pred_roc, breast_cancer_valid$diagnosis)
pred_rf <- prediction(rf_pred_roc, breast_cancer_valid$diagnosis)

# ROC Curve를 계산
perf_logit <- performance(pred_logit, "tpr", "fpr")
perf_tree <- performance(pred_tree, "tpr", "fpr")
perf_rf <- performance(pred_rf, "tpr", "fpr")

# data frame을 생성합니다
df <- data.frame(
  TPR = c(perf_logit@y.values[[1]], perf_tree@y.values[[1]], perf_rf@y.values[[1]]),
  FPR = c(perf_logit@x.values[[1]], perf_tree@x.values[[1]], perf_rf@x.values[[1]]),
  Model = c(rep("Logistic Regression", length(perf_logit@y.values[[1]])),
            rep("Decision Tree", length(perf_tree@y.values[[1]])),
            rep("Random Forest", length(perf_rf@y.values[[1]])))
)

# ROC Curve plot
ggplot(df, aes(x=FPR, y=TPR, color=Model)) +
  geom_line(size=1.2) +  
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") + 
  labs(title="ROC Curves", x="False Positive Rate", y="True Positive Rate") +
  theme_bw() +
  scale_color_manual(values=c("#0000FF80", "#FF000080", "#00800080"), 
                     breaks=c("Logistic Regression", "Decision Tree", "Random Forest"))
```

위 **ROC Curve** 를 보았을 때 $Decision\ Tree \lt Random\ Forest \approx Logistic\ Regression$ 인 것을 확인할 수 있습니다. 또한 여기서도 **Accuracy** 를 보았을 때와 동일하게 $Random\ Forest$와 $Logistic\ Regression$의 차이가 크지 않아 보이기 때문에 수치적으로 정확하게 확인해보겠습니다.

<br>

##### AUC

```{r}
# AUC
auc_logit <- performance(pred_logit, "auc")@y.values[[1]]
auc_tree <- performance(pred_tree, "auc")@y.values[[1]]
auc_rf <- performance(pred_rf, "auc")@y.values[[1]]

# AUC를 data frame으로 변환합니다
auc_df <- data.frame(Model = c("Logistic Regression", "Decision Tree", "Random Forest"),
                     AUC = c(auc_logit, auc_tree, auc_rf))

# Model 변수를 factor화 하고 level 지정.
auc_df$Model <- factor(auc_df$Model, levels=c("Random Forest", "Decision Tree", "Logistic Regression"))

# 색상을 지정
colors <- c("#0000FF80", "#FF000080", "#00800080")

# barplot
ggplot(auc_df, aes(x=Model, y=AUC, fill=Model)) +
  geom_bar(stat="identity", width=0.5, fill=colors) +
  geom_text(aes(label=round(AUC, 3)), size=4, vjust=-0.5) +
  ylim(0, 1) +
  coord_flip() +
  labs(title="Comparison of Model AUROC",y="AUROC") +
  theme_bw() +
  theme(legend.position="none", axis.title.y=element_blank()) 
```

각 모델에 대해서 **AUROC** 를 구하고 시각화를 해줬습니다.$Random\ Forest$와 $Logistic\ Regression$의 차이가 크지는 않지만 $Decision\ Tree \lt Random\ Forest \lt Logistic\ Regression$의 순서로 **AUROC** 성능을 보이는 것을 확인할 수 있습니다.

<br><br>

#### 3-1-3. Compare All

$Logistic\ Regression,\ Decision\ Tree,\ Random\ Forest$에 대해서 **Accuracy** 와 **AUC** 를 비교했습니다. 이를 동시에 비교해 보겠습니다.

```{r}
# 각각의 그래프를 생성
p1 <- ggplot(acc_df, aes(x=Accuracy, y=Model, fill=Model)) +
  geom_bar(stat="identity", width=0.5, fill=colors) +
  geom_text(aes(label=round(Accuracy, 3)), size=5) +
  xlim(0, 1) +
  labs(title="Accuracy") +
  theme_bw() +
  theme(legend.position="none", axis.title.x=element_blank(), axis.title.y=element_blank())

p2 <- ggplot(auc_df, aes(x=AUC, y=Model, fill=Model)) +
  geom_bar(stat="identity", width=0.5, fill=colors) +
  geom_text(aes(label=round(AUC, 3)), size=5)  +
  xlim(0, 1) +
  labs(title="AUROC") +
  theme_bw() +
  theme(legend.position="none", axis.title.x=element_blank(), axis.title.y=element_blank()) 

# 하나로 변환
grid.arrange(p1, p2, ncol=1)
```

> $Logistic\ Regression,\ Random\ Forest$ 두 모델이 상대적으로 $Decision\ Tree$에 비해서 성능이 좋게 나타납니다. $Logistic\ Regression$이 $Random\ Forest$에 비해서 미미하지만 더욱 좋은 성능을 보이고 있습니다. 따라서 모형의 안정성과 해석적인 부분을 고려했을 때, $Logistic\ Regression$을 이용하여 Scoring model을 개발하는 것이 바람직하다는 판단을 했습니다.

<br><br>

### 3-2. Enhance Logistic Regression Model

$Logistic\ Regression$을 학습할 때, cutoff를 0.5로 지정하여 트리모델 간의 동일한 조건 하에 비교를 진행하였는데, $Logistic\ Regression$에 대해서 **cut-off** 값을 다양하게 하여 비교를 했습니다.

<br>

##### Change cutoff value

```{r, warning=FALSE}
# 변수 선택 방법 설정
methods <- c("none", "forward", "backward", "both")

# 절단값 설정
cutoffs <- seq(0.4, 0.6, by = 0.05)

# 결과를 저장할 데이터 프레임 생성
results <- data.frame()

# 각 변수 선택 방법에 대해
for (method in methods) {
  # 변수 선택
  if (method == "none") {
    model <- glm(formula, data=breast_cancer_train, family=binomial)
  } else {
    model <- step(glm(formula, data=breast_cancer_train, family=binomial), direction=method, trace=0)
  }
  
  # 각 절단값에 대해
  for (cutoff in cutoffs) {
    # 예측 생성
    pred_prob <- predict(model, newdata = breast_cancer_valid, type = "response")
    pred_class <- ifelse(pred_prob > cutoff, "M", "B")
    
    # 정확도 계산
    acc <- mean(pred_class == breast_cancer_valid$diagnosis)
    
    # AUROC 계산
    pred <- prediction(pred_prob, breast_cancer_valid$diagnosis)
    perf <- performance(pred, measure = "auc")
    auroc <- perf@y.values[[1]]  # AUROC 값
    
    # '양성'과 '악성' 진단 결과에 대한 예측 확률을 분리합니다
    pred_prob_B <- pred_prob[breast_cancer_valid$diagnosis == "B"]
    pred_prob_M <- pred_prob[breast_cancer_valid$diagnosis == "M"]
    
    # AIC 계산
    aic <- model$aic
    
    # 결과 저장
    results <- rbind(results, data.frame(Method=method, Cutoff=cutoff, Accuracy=acc, AUROC=auroc, AIC=aic))
  }
}

# 결과 출력
print(results)
```

위에서 ML 모형과의 비교를 할 때, **cut-off** 값을 0.5로 설정했고, 이번에는 \_\_cut-off\_\_값에 변화를 주면서 차이를 확인했는데, 유의미한 변화가 보이지 않아서 기존에 했던 0.5로 **cut-off** 값을 확정지어서 진행했습니다.

<br><br>

##### Compare AIC

```{r, warning=FALSE}
# 변수 선택 방법 설정
methods <- c("none", "forward", "backward", "both")

# 절단값 설정
cutoff <- 0.5

# 결과를 저장할 데이터 프레임 생성
results <- data.frame()

# 각 변수 선택 방법에 대해
for (method in methods) {
  # 변수 선택
  if (method == "none") {
    model <- glm(formula, data=breast_cancer_train, family=binomial())
  } else {
    model <- step(glm(formula, data=breast_cancer_train, family=binomial()), direction=method, trace=0)
  }
  
  # 예측 생성
  pred_prob <- predict(model, newdata = breast_cancer_valid, type = "response")
  pred_class <- ifelse(pred_prob > cutoff, "M", "B")
  
  # 정확도 계산
  acc <- mean(pred_class == breast_cancer_valid$diagnosis)
  
  # AUROC 계산
  pred <- prediction(pred_prob, breast_cancer_valid$diagnosis)
  perf <- performance(pred, measure = "auc")
  auroc <- perf@y.values[[1]]  # AUROC 값
  
  # AIC 계산
  aic <- model$aic
  
  # 결과 저장
  results <- rbind(results, data.frame(Method=method, Cutoff=cutoff, Accuracy=acc, AUROC=auroc, AIC=aic))
}

# 결과 출력
print(results)
```

**Accuracy**, **AUROC** 값은 모델 간의 차이가 유의미하지 않아 **AIC** 가 낮은 model 중 \_\_backward\_\_를 사용한 $Logistic\ Regression$ 모형을 이용해서 평점표 모형을 개발하겠습니다.

<br><br>

## 4. Scoring Model with Logistic model

### 4-1. 2nd time variable selection

```{r}
# Model
(model <- step(glm(formula, data=breast_cancer_train, family=binomial), direction="backward"))
```

`backward elimination`을 통해서 기존의 12개의 변수에서 `fractal_dimension_mean`, `smoothness_se`, `compactness_se`, `symmetry_se`를 제외한 8개의 변수가 최종적으로 선택되었습니다.

-   종속변수
    -   **diagnosis**: 진단 결과("B": 양성, "M": 악성)
-   독립변수
    -   **radius_mean**: 중심에서 둘레까지의 거리의 평균
    -   **texture_mean**: gray-scale 값의 평균
    -   **smoothness_mean**: 반지름 길이의 지역 변동의 평균
    -   **compactness_mean**: $radius^2/area-1.0$의 평균
    -   **symmetry_mean**: 대칭성의 평균
    -   **radius_se**: 중심에서 둘레까지의 거리의 표준오차
    -   **texture_se**: gray-scale 값의 표준오차
    -   **fractal_dimension_se**: $(costline\ approximation)^-1$의 표준오차

<br><br>

### 4-2. Scorecard

```{r}
# 최종 변수 리스트
var_list <- c('radius_mean', 'texture_mean', 'smoothness_mean', 'compactness_mean', 'symmetry_mean', 'radius_se', 'texture_se', 'fractal_dimension_se')

# 분포 기반 범주화 및 범주 범위 출력
for (var in var_list) {
  # 범주화
  breast_cancer_train <- breast_cancer_train %>%
    mutate(!!paste0(var, "_cat") := cut(!!sym(var), breaks=quantile(!!sym(var), probs=seq(0, 1, by=0.25)), include.lowest=TRUE))
  
  # 범주 범위 출력
  cat(paste("Variable:", var, "\n"))
  print(summary(as.factor(breast_cancer_train[[paste0(var, "_cat")]])))
}
```

<br><br>

[변수별 범주 설정]

| Variable             |                  1 |                 2 |                3 |               4 |
|:--------------|--------------:|--------------:|--------------:|--------------:|
| radius_mean          |        [6.98,11.6] |       (11.6,13.2] |      (13.2,15.4] |     (15.4,27.2] |
| texture_mean         |        [10.7,16.2] |       (16.2,18.9] |      (18.9,21.8] |     (21.8,33.6] |
| smoothness_mean      |     [0.0526,0.085] |    (0.085,0.0946] |   (0.0946,0.105] |   (0.105,0.163] |
| compactness_mean     |    [0.0194,0.0631] |   (0.0631,0.0896] |    (0.0896,0.13] |    (0.13,0.287] |
| symmetry_mean        |      [0.117,0.163] |     (0.163,0.179] |    (0.179,0.195] |   (0.195,0.304] |
| radius_se            |      [0.112,0.232] |     (0.232,0.316] |    (0.316,0.468] |    (0.468,1.51] |
| texture_se           |       [0.36,0.856] |      (0.856,1.14] |      (1.14,1.48] |     (1.48,3.65] |
| fractal_dimension_se | [0.000895,0.00222] | (0.00222,0.00313] | (0.00313,0.0045] | (0.0045,0.0298] |

<br>

```{r}
# 회귀 모델의 계수값
model[1]
```

<br>

<br><br>

#### 4-2-1. 1st Scoring Model

각 범주를 그대로 점수로 가져가봤습니다.

<br>

| Variable             |   1 |   2 |   3 |   4 |
|:---------------------|----:|----:|----:|----:|
| radius_mean          |   1 |   2 |   3 |   4 |
| texture_mean         |   1 |   2 |   3 |   4 |
| smoothness_mean      |   1 |   2 |   3 |   4 |
| compactness_mean     |   1 |   2 |   3 |   4 |
| symmetry_mean        |   1 |   2 |   3 |   4 |
| radius_se            |   1 |   2 |   3 |   4 |
| texture_se           |   1 |   2 |   3 |   4 |
| fractal_dimension_se |   1 |   2 |   3 |   4 |

<br><br>

```{r}
# valdation 데이터 이용
selected_data <- breast_cancer_valid %>%
  select(diagnosis, radius_mean, texture_mean, smoothness_mean, compactness_mean, 
         symmetry_mean,radius_se, texture_se, fractal_dimension_se)

head(selected_data)
```

```{r}
# 각 변수에 대해 주어진 범위에 따라 클래스와 점수를 부여
score_01_data <- selected_data %>%
  mutate(radius_mean_score = ifelse(radius_mean <= 10, 1,
                                    ifelse(radius_mean <= 13, 2,
                                           ifelse(radius_mean <= 16, 3, 4))),

         texture_mean_score = ifelse(texture_mean <= 16, 1,
                                     ifelse(texture_mean <= 19, 2,
                                            ifelse(texture_mean <= 22, 20.35, 27.7))),
                        
         smoothness_mean_score = ifelse(smoothness_mean <= 0.08, 1,
                                        ifelse(smoothness_mean <= 0.09, 2,
                                               ifelse(smoothness_mean <= 0.12, 3, 4))),

         compactness_mean_score = ifelse(compactness_mean <= 0.06, 1,
                                         ifelse(compactness_mean <= 0.09, 2,
                                                ifelse(compactness_mean <= 16, 3, 4))),

         symmetry_mean_score = ifelse(symmetry_mean <= 0.16, 1,
                                      ifelse(symmetry_mean <= 0.18, 2,
                                             ifelse(symmetry_mean <= 0.20, 3, 4))),

         radius_se_score = ifelse(radius_se <= 0.22, 1,
                                  ifelse(radius_se <= 0.33, 2,
                                         ifelse(radius_se <= 0.44, 3, 4))),

         texture_se_score = ifelse(texture_se <= 0.90, 1,
                                   ifelse(texture_se <= 1.20, 2,
                                          ifelse(texture_se <= 1.50, 3, 4))),

         fractal_dimension_se_score = ifelse(fractal_dimension_se <= 0.002, 1,
                                             ifelse(fractal_dimension_se <= 0.003, 2,
                                                    ifelse(fractal_dimension_se <= 0.004, 3, 4))))


# _score로 끝나는 모든 변수들의 합을 계산하여 score라는 새로운 열을 생성
score_01_vars <- grep("_score$", names(score_01_data), value = TRUE)

score_01_data <- score_01_data %>% mutate(score = rowSums(.[score_01_vars]))
```

```{r}
group_B <- score_01_data$score[score_01_data$diagnosis == "B"]
group_M <- score_01_data$score[score_01_data$diagnosis == "M"]

# KS 통계량 계산
ks_result_01 <- ks.test(group_B, group_M)

# KS 통계량 출력
print(ks_result_01$statistic)
```

```{r}
# 누적 B/M 구성비 분포 그래프 그리기
ggplot() +
  stat_ecdf(data = data.frame(score = group_B, group = "B"), aes(score, colour = group)) +
  stat_ecdf(data = data.frame(score = group_M, group = "M"), aes(score, colour = group)) +
  labs(x = "Score", y = "Cumulative Proportion", 
       title = "Cumulative Distribution Plot for Score",
       subtitle = "Blue: Group B, Red: Group M")
```

```{r}
# 'B'와 'M' 진단 그룹의 실제 라벨 생성
actual <- ifelse(score_01_data$diagnosis == "B", 0, 1)

# 예측 객체 생성
pred <- prediction(score_01_data$score, actual)

# ROC 곡선 계산
roc_obj <- performance(pred, "tpr", "fpr")

# AUROC 값 계산
auc_obj <- performance(pred, "auc")

# AUROC 값 출력
print(auc_obj@y.values[[1]])

```

> 단순히 점수를 1, 2, 3, 4로 두었을 때, KS통계량은 0.5673749이고, AUROC가 0.8470786이 나왔습니다. 그러나 만족스러운 수치는 아니므로 다른 방법으로 보완해보겠습니다.

<br><br>

#### 4-2-2. 2nd Scoring Model

두 번째 평점표 모형은 각 class의 구간의 중앙값으로 설정하고 계수의 방향성까지 고려해줬습니다.

<br>

| Variable             |                  1 |                 2 |                3 |               4 |
|:--------------|--------------:|--------------:|--------------:|--------------:|
| radius_mean          |        [6.98,11.6] |       (11.6,13.2] |      (13.2,15.4] |     (15.4,27.2] |
| texture_mean         |        [10.7,16.2] |       (16.2,18.9] |      (18.9,21.8] |     (21.8,33.6] |
| smoothness_mean      |     [0.0526,0.085] |    (0.085,0.0946] |   (0.0946,0.105] |   (0.105,0.163] |
| compactness_mean     |    [0.0194,0.0631] |   (0.0631,0.0896] |    (0.0896,0.13] |    (0.13,0.287] |
| symmetry_mean        |      [0.117,0.163] |     (0.163,0.179] |    (0.179,0.195] |   (0.195,0.304] |
| radius_se            |      [0.112,0.232] |     (0.232,0.316] |    (0.316,0.468] |    (0.468,1.51] |
| texture_se           |       [0.36,0.856] |      (0.856,1.14] |      (1.14,1.48] |     (1.48,3.65] |
| fractal_dimension_se | [0.000895,0.00222] | (0.00222,0.00313] | (0.00313,0.0045] | (0.0045,0.0298] |

<br>

| Variable             |          1 |         2 |         3 |        4 |
|:---------------------|-----------:|----------:|----------:|---------:|
| radius_mean          |       9.29 |      12.4 |      14.3 |     21.3 |
| texture_mean         |      13.45 |     17.55 |     20.35 |     27.7 |
| smoothness_mean      |     0.0688 |    0.0898 |    0.0998 |    0.134 |
| compactness_mean     |    0.04125 |   0.07635 |    0.1098 |   0.2085 |
| symmetry_mean        |       0.14 |     0.171 |     0.187 |   0.2495 |
| radius_se            |      0.172 |     0.274 |     0.392 |    0.989 |
| texture_se           |     -0.608 |    -0.998 |     -1.31 |   -2.565 |
| fractal_dimension_se | -0.0015575 | -0.002675 | -0.003815 | -0.01715 |

<br>

```{r}
# 각 변수에 대해 주어진 범위에 따라 클래스와 점수를 부여
score_02_data <- selected_data %>%
  mutate(radius_mean_score = ifelse(radius_mean <= 10, 9.29,
                                    ifelse(radius_mean <= 13, 12.4,
                                           ifelse(radius_mean <= 16, 14.3, 21.3))),

         texture_mean_score = ifelse(texture_mean <= 16, 13.45,
                                     ifelse(texture_mean <= 19, 17.55,
                                            ifelse(texture_mean <= 22, 20.35, 27.7))),
                        
         smoothness_mean_score = ifelse(smoothness_mean <= 0.08, 0.0688,
                                        ifelse(smoothness_mean <= 0.09, 0.0898,
                                               ifelse(smoothness_mean <= 0.12, 0.0998, 0.134))),

         compactness_mean_score = ifelse(compactness_mean <= 0.06, 0.04125,
                                         ifelse(compactness_mean <= 0.09, 0.07635,
                                                ifelse(compactness_mean <= 16, 0.1098, 0.2085))),

         symmetry_mean_score = ifelse(symmetry_mean <= 0.16, 0.14,
                                      ifelse(symmetry_mean <= 0.18, 0.171,
                                             ifelse(symmetry_mean <= 0.20, 0.187, 0.2495))),

         radius_se_score = ifelse(radius_se <= 0.22, 0.172,
                                  ifelse(radius_se <= 0.33, 0.274,
                                         ifelse(radius_se <= 0.44, 0.392, 0.989))),

         texture_se_score = ifelse(texture_se <= 0.90, -0.608,
                                   ifelse(texture_se <= 1.20, -0.998,
                                          ifelse(texture_se <= 1.50, -1.31, -2.565))),

         fractal_dimension_se_score = ifelse(fractal_dimension_se <= 0.002, -0.0015575,
                                             ifelse(fractal_dimension_se <= 0.003, -0.002675,
                                                    ifelse(fractal_dimension_se <= 0.004, -0.003815, -0.01715))))


# _score로 끝나는 모든 변수들의 합을 계산하여 score라는 새로운 열을 생성
score_02_vars <- grep("_score$", names(score_02_data), value = TRUE)

score_02_data <- score_02_data %>% mutate(score = rowSums(.[score_02_vars]))
```

```{r}
group_B <- score_02_data$score[score_02_data$diagnosis == "B"]
group_M <- score_02_data$score[score_02_data$diagnosis == "M"]

# KS 통계량 계산
ks_result_02 <- ks.test(group_B, group_M)

# KS 통계량 출력
print(ks_result_02$statistic)
```

```{r}
# 누적 B/M 구성비 분포 그래프 그리기
ggplot() +
  stat_ecdf(data = data.frame(score = group_B, group = "B"), aes(score, colour = group)) +
  stat_ecdf(data = data.frame(score = group_M, group = "M"), aes(score, colour = group)) +
  labs(x = "Score", y = "Cumulative Proportion", 
       title = "Cumulative Distribution Plot for Score",
       subtitle = "Blue: Group B, Red: Group M")
```

```{r}
# 'B'와 'M' 진단 그룹의 실제 라벨 생성
actual <- ifelse(score_02_data$diagnosis == "B", 0, 1)

# 예측 객체 생성
pred <- prediction(score_02_data$score, actual)

# ROC 곡선 계산
roc_obj <- performance(pred, "tpr", "fpr")

# AUROC 값 계산
auc_obj <- performance(pred, "auc")

# AUROC 값 출력
print(auc_obj@y.values[[1]])
```

> 2번 모델은 KS 통계량이 0.7545429, 1번 모델은 0.5673749로 2번 모델이 더 높고, 2번 모델의 AUROC값이 0.9180878로 1번 모델의 AUROC값 0.8470786보다 높았음이 확인이 됩니다.

> 따라서 2번 모델이 더 뛰어난 성능을 보임을 확인했습니다. 더 높은 성능을 위해서 스코어에 계수값을 곱해줘 보겠습니다.

<br><br>

#### 4-2-3. 3rd Scoring Model

3번째 평점표 모형은 두 번째 모형에 각 변수의 계수를 곱해주었습니다. (소수 첫번째까지 사용)

| Variable             |                  1 |                 2 |                3 |               4 |
|:--------------|--------------:|--------------:|--------------:|--------------:|
| radius_mean          |        [6.98,11.6] |       (11.6,13.2] |      (13.2,15.4] |     (15.4,27.2] |
| texture_mean         |        [10.7,16.2] |       (16.2,18.9] |      (18.9,21.8] |     (21.8,33.6] |
| smoothness_mean      |     [0.0526,0.085] |    (0.085,0.0946] |   (0.0946,0.105] |   (0.105,0.163] |
| compactness_mean     |    [0.0194,0.0631] |   (0.0631,0.0896] |    (0.0896,0.13] |    (0.13,0.287] |
| symmetry_mean        |      [0.117,0.163] |     (0.163,0.179] |    (0.179,0.195] |   (0.195,0.304] |
| radius_se            |      [0.112,0.232] |     (0.232,0.316] |    (0.316,0.468] |    (0.468,1.51] |
| texture_se           |       [0.36,0.856] |      (0.856,1.14] |      (1.14,1.48] |     (1.48,3.65] |
| fractal_dimension_se | [0.000895,0.00222] | (0.00222,0.00313] | (0.00313,0.0045] | (0.0045,0.0298] |

<br>

| Variable             |    1 |    2 |    3 |    4 |      coef |
|:---------------------|-----:|-----:|-----:|-----:|----------:|
| radius_mean          |  9.5 | 12.7 | 14.6 | 21.8 |    1.0262 |
| texture_mean         |  5.8 |  7.6 |  8.8 | 12.0 |    0.4345 |
| smoothness_mean      |  5.4 |  7.1 |  7.9 | 10.6 |   79.7946 |
| compactness_mean     |  1.1 |  2.1 |  3.0 |  5.8 |   27.9530 |
| symmetry_mean        |  2.5 |  3.1 |  3.4 |  4.5 |   18.3689 |
| radius_se            |  0.8 |  1.2 |  1.8 |  4.6 |    4.7003 |
| texture_se           | -0.8 | -1.4 | -1.9 | -3.7 |   -1.4729 |
| fractal_dimension_se | -0.5 | -1.0 | -1.4 | -6.4 | -375.6956 |

```{r}
# 각 변수에 대해 주어진 범위에 따라 클래스와 점수를 부여
score_03_data <- selected_data %>%
  mutate(radius_mean_score = ifelse(radius_mean <= 10, 9.5,
                                    ifelse(radius_mean <= 13, 12.7,
                                           ifelse(radius_mean <= 16, 14.6, 21.8))),

         texture_mean_score = ifelse(texture_mean <= 16, 5.8,
                                     ifelse(texture_mean <= 19, 7.6,
                                            ifelse(texture_mean <= 22, 8.8, 12.0))),
                        
         smoothness_mean_score = ifelse(smoothness_mean <= 0.08, 5.4,
                                        ifelse(smoothness_mean <= 0.09, 7.1,
                                               ifelse(smoothness_mean <= 0.12, 7.9, 10.6))),

         compactness_mean_score = ifelse(compactness_mean <= 0.06, 1.1,
                                         ifelse(compactness_mean <= 0.09, 2.1,
                                                ifelse(compactness_mean <= 16, 3.0, 5.8))),

         symmetry_mean_score = ifelse(symmetry_mean <= 0.16, 2.5,
                                      ifelse(symmetry_mean <= 0.18, 3.1,
                                             ifelse(symmetry_mean <= 0.20, 3.4, 4.5))),

         radius_se_score = ifelse(radius_se <= 0.22, 0.8,
                                  ifelse(radius_se <= 0.33, 1.2,
                                         ifelse(radius_se <= 0.44, 1.8, 4.6))),

         texture_se_score = ifelse(texture_se <= 0.90, -0.8,
                                   ifelse(texture_se <= 1.20, -1.4,
                                          ifelse(texture_se <= 1.50, -1.9, -3.7))),

         fractal_dimension_se_score = ifelse(fractal_dimension_se <= 0.002, -0.5,
                                             ifelse(fractal_dimension_se <= 0.003, -1.0,
                                                    ifelse(fractal_dimension_se <= 0.004, -1.4, -6.4))))


# _score로 끝나는 모든 변수들의 합을 계산하여 score라는 새로운 열을 생성
score_03_vars <- grep("_score$", names(score_03_data), value = TRUE)

score_03_data <- score_03_data %>% mutate(score = rowSums(.[score_03_vars]))

```

```{r}
group_B <- score_03_data$score[score_03_data$diagnosis == "B"]
group_M <- score_03_data$score[score_03_data$diagnosis == "M"]

# KS 통계량 계산
ks_result_03 <- ks.test(group_B, group_M)

# KS 통계량 출력
print(ks_result_03$statistic)

```

```{r}
# 누적 B/M 구성비 분포 그래프 그리기
ggplot() +
  stat_ecdf(data = data.frame(score = group_B, group = "B"), aes(score, colour = group)) +
  stat_ecdf(data = data.frame(score = group_M, group = "M"), aes(score, colour = group)) +
  labs(x = "Score", y = "Cumulative Proportion", 
       title = "Cumulative Distribution Plot for Score",
       subtitle = "Blue: Group B, Red: Group M")

```

```{r}
# 'B'와 'M' 진단 그룹의 실제 라벨 생성
actual <- ifelse(score_03_data$diagnosis == "B", 0, 1)

# 예측 객체 생성
pred <- prediction(score_03_data$score, actual)

# ROC 곡선 계산
roc_obj <- performance(pred, "tpr", "fpr")

# AUROC 값 계산
auc_obj <- performance(pred, "auc")

# AUROC 값 출력
print(auc_obj@y.values[[1]])
```

> 3개의 스코어링 모델 중 2, 3번 모델이 1번 모델에 비해서 KS 통계량이랑 AUROC값이 높아 성능이 좋은 것으로 확인됩니다.

> 그 중 3번 모델이 AUROC가 0.9534526로 2번 모델보다 높아서, 성능이 뛰어남을 확인했습니다. 따라서 3번 모델을 스코어링 모델로 사용하겠습니다.

<br><br>

[Scorecard]

| Variable             |             range | class | score |
|:---------------------|------------------:|------:|------:|
| radius_mean          |          [0,11.6] |     1 |   9.5 |
| radius_mean          |       (11.6,13.2] |     2 |  12.7 |
| radius_mean          |       (13.2,15.4] |     3 |  14.6 |
| radius_mean          |   (15.4,$\infty$) |     4 |  21.8 |
| texture_mean         |          [0,16.2] |     1 |   5.8 |
| texture_mean         |       (16.2,18.9] |     2 |   7.6 |
| texture_mean         |       (18.9,21.8] |     3 |   8.8 |
| texture_mean         |   (21.8,$\infty$) |     4 |  12.0 |
| smoothness_mean      |         [0,0.085] |     1 |   5.4 |
| smoothness_mean      |    (0.085,0.0946] |     2 |   7.1 |
| smoothness_mean      |    (0.0946,0.105] |     3 |   7.9 |
| smoothness_mean      |  (0.105,$\infty$] |     4 |  10.6 |
| compactness_mean     |        [0,0.0631] |     1 |   1.1 |
| compactness_mean     |   (0.0631,0.0896] |     2 |   2.1 |
| compactness_mean     |     (0.0896,0.13] |     3 |   3.0 |
| compactness_mean     |   (0.13,$\infty$) |     4 |   5.8 |
| symmetry_mean        |         [0,0.163] |     1 |   2.5 |
| symmetry_mean        |     (0.163,0.179] |     2 |   3.1 |
| symmetry_mean        |     (0.179,0.195] |     3 |   3.4 |
| symmetry_mean        |  (0.195,$\infty$] |     4 |   4.5 |
| radius_se            |         [0,0.232] |     1 |   0.8 |
| radius_se            |     (0.232,0.316] |     2 |   1.2 |
| radius_se            |     (0.316,0.468] |     3 |   1.8 |
| radius_se            |  (0.468,$\infty$) |     4 |   4.6 |
| texture_se           |         [0,0.856] |     1 |  -0.8 |
| texture_se           |      (0.856,1.14] |     2 |  -1.4 |
| texture_se           |       (1.14,1.48] |     3 |  -1.9 |
| texture_se           |   (1.48,$\infty$) |     4 |  -3.7 |
| fractal_dimension_se |       [0,0.00222] |     1 |  -0.5 |
| fractal_dimension_se | (0.00222,0.00313] |     2 |  -1.0 |
| fractal_dimension_se |  (0.00313,0.0045] |     3 |  -1.4 |
| fractal_dimension_se | (0.0045,$\infty$] |     4 |  -6.4 |

<br>

## 5. Scoring Model 적용

### 5-1. AUROC 이용한 Score 임계치 구하기

ROC 곡선은 여러 임계값에서의 진짜 양성률(True Positive Rate, TPR)과 거짓 양성률(False Positive Rate, FPR)을 나타냅니다. 이 곡선 아래의 면적이 **AUROC** 이며, 이 값이 1에 가까울 수록 모델의 성능이 좋다고 판단합니다.

따라서 **AUROC** 값을 최대화하는 점수 임계값을 선택하면, 해당 임계값을 기준으로 양성(Benign), 악성(Malignant)을 구분하는데 사용할 수 있습니다. 이는 **ROC** 곡선 분석을 통해 수행할 수 있습니다.

```{r}
# 예측 객체 생성
pred <- prediction(score_03_data$score, actual)

# 최적의 임계값 찾기
perf <- performance(pred, "sens", "spec")
decision.values <- data.frame(cut = perf@alpha.values[[1]], 
                              sensitivity = perf@x.values[[1]], 
                              specificity = perf@y.values[[1]])
optimal.cut <- decision.values[which.max(decision.values$sensitivity + decision.values$specificity), "cut"]

# 최적의 임계값 출력
print(optimal.cut)
```

**ROC** 곡선에서 최적의 임계값을 찾는 과정을 진행했고 3번 모델을 기반으로한 score의 임계값은 \_\_35\_\_가 나옵니다.

<br><br>

### 5-2. Scoring Calculation

입력되는 환자의 데이터에 대해서 각 변수들에 대한 점수를 계산해보겠습니다. 이를 위해 변수별로 계산된 점수의 총점에 따라 예측을 하는 함수를 작성하겠습니다.

```{r}
# 함수 생성
calculate_score_and_diagnose <- function(data) {
  data <- data %>%
    mutate(radius_mean_score = ifelse(radius_mean <= 10, 9.5,
                                       ifelse(radius_mean <= 13, 12.7,
                                              ifelse(radius_mean <= 16, 14.6, 21.8))),
           texture_mean_score = ifelse(texture_mean <= 16, 5.8,
                                       ifelse(texture_mean <= 19, 7.6,
                                              ifelse(texture_mean <= 22, 8.8, 12.0))),
           smoothness_mean_score = ifelse(smoothness_mean <= 0.08, 5.4,
                                          ifelse(smoothness_mean <= 0.09, 7.1,
                                                 ifelse(smoothness_mean <= 0.12, 7.9, 10.6))),
           compactness_mean_score = ifelse(compactness_mean <= 0.06, 1.1,
                                           ifelse(compactness_mean <= 0.09, 2.1,
                                                  ifelse(compactness_mean <= 16, 3.0, 5.8))),
           symmetry_mean_score = ifelse(symmetry_mean <= 0.16, 2.5,
                                        ifelse(symmetry_mean <= 0.18, 3.1,
                                               ifelse(symmetry_mean <= 0.20, 3.4, 4.5))),
           radius_se_score = ifelse(radius_se <= 0.22, 0.8,
                                    ifelse(radius_se <= 0.33, 1.2,
                                           ifelse(radius_se <= 0.44, 1.8, 4.6))),
           texture_se_score = ifelse(texture_se <= 0.90, -0.8,
                                     ifelse(texture_se <= 1.20, -1.4,
                                            ifelse(texture_se <= 1.50, -1.9, -3.7))),
           fractal_dimension_se_score = ifelse(fractal_dimension_se <= 0.002, -0.5,
                                               ifelse(fractal_dimension_se <= 0.003, -1.0,
                                                      ifelse(fractal_dimension_se <= 0.004, -1.4, -6.4))))
  
  score_vars <- grep("_score$", names(data), value = TRUE)
  
  data <- data %>% mutate(score = rowSums(.[score_vars]))
  
  data <- data %>% mutate(diagnosis = ifelse(score > 35, "M", "B"))
  
  return(data)
}
```

<br><br>

### 5-3. Applying model

Benign(양성)인 환자와 Malignant(악성)인 환자의 데이터를 각각 선택해서 결과를 출력하겠습니다.

```{r}
# valdation 데이터 이용
sample_data <- breast_cancer_valid %>%
  select(id, diagnosis, radius_mean, texture_mean, smoothness_mean, compactness_mean, 
         symmetry_mean,radius_se, texture_se, fractal_dimension_se)

# diagnosis가 'M'인 첫 번째 행 선택
M_data <- selected_data %>% 
  filter(diagnosis == 'M') %>% 
  slice(1)

# diagnosis가 'B'인 첫 번째 행 선택
B_data <- selected_data %>% 
  filter(diagnosis == 'B') %>% 
  slice(1)

M_data # Malignant(악성=M)인 환자데이터

B_data # Benign(양성=B)인 환자데이터
```

<br>

#### Benign(양성)인 환자 데이터

Benign(양성)인 환자에 대해서 각각의 스코어링 결과를 시각화하겠습니다.

```{r, fig.width=10}
# B_data # Benign(양성=B)인 환자데이터
use_data = B_data

result <- calculate_score_and_diagnose(use_data)

# 첫번째 그래프
# "_score"로 끝나는 변수만 선택합니다.
result_score <- dplyr::select(result, ends_with("_score"))

# 데이터를 길게 변형합니다.
result_score_long <- tidyr::pivot_longer(result_score, everything(), names_to = "variable", values_to = "value")

# 막대그래프를 그립니다.
p1 <- ggplot(result_score_long, aes(x = variable, y = value)) +
  geom_bar(stat = "identity", width = 0.5) +  
  ylim(-10, 30) + 
  coord_flip() +  
  labs(x = "Variable", y = "Score for each variable", title = "Score")

# 두번째 그래프
# "score" 열만 선택합니다.
result_score <- result$score 

# 데이터 프레임을 생성합니다.
df <- data.frame(score = result_score)

# 막대그래프를 그립니다.
p2 <-  ggplot(df, aes(x = "", y = score, fill = (score > 35))) +
  geom_bar(stat = "identity", width = 0.4) +
  scale_fill_manual(values = c("TRUE" = "#6AD3D6", "FALSE" = "#F2ABA6"), labels = c("TRUE" = "Malignant", "FALSE" = "Benign"), name = "diagnosis") +
  ylim(0,50) +
  geom_hline(yintercept = 35, linetype = "dashed", color = "red") +
  geom_text(aes(label=score), vjust=-0.3, size=3.5) +
  theme_bw() +
  labs(title = "Total score", x = "Total score", y = "Score")

# 두 그래프를 합칩니다.
grid.arrange(p1, p2, ncol=2, widths = c(3, 1))  # p1과 p2의 비율을 3:1로 설정합니다.
```

왼쪽 각각의 변수에 대한 스코어를 구해 막대그래프를 출력해주었고, 오른쪽 그래프에서 각 변수들에 대한 스코어를 총합하여 35보다 작게 나옴으로 Benign(양성)으로 판정하는 모습을 보여줌으로서 원래 Benign(양성)인 환자 데이터를 넣어주었을때 Benign(양성)을 출력해줌으로 좋은 예측을 해주고 있습니다.

<br><br>

#### Malignant(악성)인 환자 데이터

Malignant(악성)인 환자에 대해서 각각의 스코어링 결과를 시각화하겠습니다.

```{r, fig.width=10}
# M_data # # Malignant(악성=M)인 환자데이터
use_data = M_data

result <- calculate_score_and_diagnose(use_data)

# 첫번째 그래프
# "_score"로 끝나는 변수만 선택합니다.
result_score <- dplyr::select(result, ends_with("_score"))

# 데이터를 길게 변형합니다.
result_score_long <- tidyr::pivot_longer(result_score, everything(), names_to = "variable", values_to = "value")

# 막대그래프를 그립니다.
p1 <- ggplot(result_score_long, aes(x = variable, y = value)) +
  geom_bar(stat = "identity", width = 0.5) +  
  ylim(-10, 30) + 
  coord_flip() +  
  labs(x = "Variable", y = "Score for each variable", title = "Score")

# 두번째 그래프
# "score" 열만 선택합니다.
result_score <- result$score 

# 데이터 프레임을 생성합니다.
df <- data.frame(score = result_score)

# 막대그래프를 그립니다.
p2 <-  ggplot(df, aes(x = "", y = score, fill = (score > 35))) +
  geom_bar(stat = "identity", width = 0.4) +
  scale_fill_manual(values = c("TRUE" = "#6AD3D6", "FALSE" = "#F2ABA6"), labels = c("TRUE" = "Malignant", "FALSE" = "Benign"), name = "diagnosis") +
  ylim(0,50) +
  geom_hline(yintercept = 35, linetype = "dashed", color = "red") +
  geom_text(aes(label=score), vjust=-0.3, size=3.5) +
  theme_bw() +
  labs(title = "Total score", x = "Total score", y = "Score")

# 두 그래프를 합칩니다.
grid.arrange(p1, p2, ncol=2, widths = c(3, 1))  # p1과 p2의 비율을 3:1로 설정합니다.
```

오른쪽 그래프에서 각 변수들에 대한 스코어를 총합하여 35보다 크게 나옴으로 Malignant(악성)으로 판정하는 모습을 보여줌으로서 원래 Malignant(악성)인 환자 데이터를 넣어주었을때 Malignant를 출력해줌으로 좋은 예측을 해주고 있습니다.

<br><br>

## 6. 요약 및 결론

데이터 전처리 과정을 통해서 30개의 변수에서 12개의 변수로 축소를 시켰고, 이를 기반으로 Modeling을 진행했습니다.

Modeling 부분에서는 $Logistic\ Regression,\ Decision\ Tree,\ Random\ Forest$ 3가지 모델을 정확도와 **ROC**, \_\_AUC\_\_을 통해서 $Logistic\ Model$을 기반으로 스코어링 모델을 개발한다는 판단을 했습니다.

그 후 $Logistic\ Model$의 능력을 향상시키기 위해서 변수 선택을 2차적으로 진행해서 8개의 변수로 한 번 더 축소시켰습니다.

최종 선택된 변수들을 토대로 각 변수에 대한 분포를 범주화해서 스코어링했고, 3가지 모델 중에서 선택된 최종 스코어링 모델을 기반으로 예측을 진행했습니다.

이 과정에 의해 모델이 높은 정확도를 보임을 확인했고, 결론적으로 유방암에 대한 오진율을 줄일 수 있다는 판단을 하게 되었다.

이를 통해 오진율이 높은 유방암에 대해서 오진율을 줄여 사회적 비용을 감소시킬 수 있다는 기대를 하게되었습니다.
